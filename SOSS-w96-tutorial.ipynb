{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78884c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "\n",
    "from jwst import datamodels\n",
    "\n",
    "import corner\n",
    "\n",
    "import juliet\n",
    "import transitspectroscopy as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ece437",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd617f",
   "metadata": {},
   "source": [
    "# A first, quick-look at the data\n",
    "\n",
    "There are many data products for JWST and that can be confusing. Here we will focus on two main products:\n",
    "\n",
    "- The `*uncal.fits` products (really, the uncalibrated products; think of \"raw\" data).\n",
    "- The `*rateints.fits` products (think, the \"detector, linearity-corrected data\").\n",
    "\n",
    "Let's first read one segment of the uncalibrated products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c77905",
   "metadata": {},
   "outputs": [],
   "source": [
    "tso_uncal1 = datamodels.RampModel(datafolder + 'jw02734002001_04101_00001-seg001_nis_uncal.fits')\n",
    "tso_uncal2 = datamodels.RampModel(datafolder + 'jw02734002001_04101_00001-seg002_nis_uncal.fits')\n",
    "tso_uncal3 = datamodels.RampModel(datafolder + 'jw02734002001_04101_00001-seg003_nis_uncal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tso_uncal1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6adaaa",
   "metadata": {},
   "source": [
    "The dimensions of each segment are `(nintegrations, ngroups, nrows, ncolumns)`. Let's put all together in one single array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d954cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncal data on a single array:\n",
    "tso_uncal = np.vstack((tso_uncal1.data, tso_uncal2.data))\n",
    "tso_uncal = np.vstack((tso_uncal, tso_uncal3.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tso_uncal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5164f",
   "metadata": {},
   "source": [
    "Let's plot how a single pixel's ramp looks like on a single integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3.5))\n",
    "\n",
    "group_index = np.arange(tso_uncal.shape[1]) + 1\n",
    "\n",
    "plt.plot(group_index, tso_uncal[10, :, 50, 1500], 'o-', color = 'cornflowerblue')\n",
    "plt.plot(group_index, tso_uncal[11, :, 50, 1500], 'o-', color = 'forestgreen')\n",
    "plt.plot(group_index, tso_uncal[12, :, 50, 1500], 'o-', color = 'orangered')\n",
    "\n",
    "plt.xlim(0.8, 14.2)\n",
    "plt.xticks(range(1,15), fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Counts', fontsize = 18)\n",
    "plt.xlabel('Group number', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78e8fd",
   "metadata": {},
   "source": [
    "Those _appear_ to be nice, linear ramps --- let's check if this is true. Let's fit a line to the first `n=3` groups and remove that from the rest of the ramp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3.5))\n",
    "\n",
    "n = 14 # Groups to fit a line to\n",
    "\n",
    "coeff1 = np.polyfit(group_index[:n], tso_uncal[10, :n, 50, 1500], 1)\n",
    "val1 = np.polyval(coeff1, group_index)\n",
    "plt.plot(group_index, tso_uncal[10, :, 50, 1500] - val1, 'o-', color = 'cornflowerblue')\n",
    "\n",
    "coeff2 = np.polyfit(group_index[:n], tso_uncal[11, :n, 50, 1500], 1)\n",
    "val2 = np.polyval(coeff2, group_index)\n",
    "plt.plot(group_index, tso_uncal[11, :, 50, 1500] - val2, 'o-', color = 'forestgreen')\n",
    "\n",
    "coeff3 = np.polyfit(group_index[:n], tso_uncal[12, :n, 50, 1500], 1)\n",
    "val3 = np.polyval(coeff3, group_index)\n",
    "plt.plot(group_index, tso_uncal[12, :, 50, 1500] - val3, 'o-', color = 'orangered')\n",
    "\n",
    "plt.xlim(0.8, 14.2)\n",
    "plt.xticks(range(1,15), fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Counts - Linear fit', fontsize = 18)\n",
    "plt.xlabel('Group number', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a34ad",
   "metadata": {},
   "source": [
    "Let's do the same for _all_ integrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.zeros([tso_uncal.shape[0], len(group_index)])\n",
    "\n",
    "for i in range(tso_uncal.shape[0]):\n",
    "    \n",
    "    coeff = np.polyfit(group_index[:n], tso_uncal[i, :n, 50, 1500], 1)\n",
    "    val = np.polyval(coeff, group_index)\n",
    "    residuals[i, :] = tso_uncal[i, :, 50, 1500] - val\n",
    "    plt.plot(group_index, residuals[i, :], '.-', color = 'black', alpha = 0.1)\n",
    "    \n",
    "median_residuals = np.nanmedian(residuals, axis = 0)\n",
    "plt.plot(group_index, median_residuals, color = 'orangered', lw = 3)\n",
    "\n",
    "plt.xlim(0.8, 14.2)\n",
    "plt.xticks(range(1,15), fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Counts - Linear fit', fontsize = 18)\n",
    "plt.xlabel('Group number', fontsize = 18)\n",
    "\n",
    "plt.ylim(-75, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67a0bc",
   "metadata": {},
   "source": [
    "Very clearly a non-linear ramp! This is the case with every JWST dataset --- they are mostly non-linear throughout a ramp; good news is we know how to correct it.\n",
    "\n",
    "The JWST pipeline produces the bias-corrected, linearity-corrected, dark-corrected, etc., _ramps/rates_ of those up-the-ramp samples (i.e., the slopes of the \"linearized\" counts). How the pipeline goes from these uncalibrated ramps to full calibrated ramps, see [this video](https://exoplanet-talks.org/talk/365) (slides [here](https://ers-transit.github.io/talks/hackathon/ers-hackathon-day1-espinoza-what-to-expect.pdf)). \n",
    "\n",
    "These calibrated data are accessible directly from the *rateints.fits files below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ef174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using datamodels:\n",
    "tso1 = datamodels.open(datafolder + 'jw02734002001_04101_00001-seg001_nis_rateints.fits')\n",
    "tso2 = datamodels.open(datafolder + 'jw02734002001_04101_00001-seg002_nis_rateints.fits')\n",
    "tso3 = datamodels.open(datafolder + 'jw02734002001_04101_00001-seg003_nis_rateints.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tso1.search('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c03aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data on a single array:\n",
    "tso = np.vstack((tso1.data, tso2.data))\n",
    "tso = np.vstack((tso, tso3.data))\n",
    "\n",
    "# Errors:\n",
    "tso_err = np.vstack((tso1.err, tso2.err))\n",
    "tso_err = np.vstack((tso_err, tso3.err))\n",
    "\n",
    "# Data-quality flags:\n",
    "tso_dq = np.vstack((tso1.dq, tso2.dq))\n",
    "tso_dq = np.vstack((tso_dq, tso3.dq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the median frame:\n",
    "median_tso = np.median(tso, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613dee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "im = plt.imshow(median_tso, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa06b7f",
   "metadata": {},
   "source": [
    "Is the transit there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1071104",
   "metadata": {},
   "outputs": [],
   "source": [
    "postage = tso[:, 20:60, 1500:1550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf823e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.sum(postage, axis = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750cf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3.5))\n",
    "\n",
    "plt.plot(timeseries / np.median(timeseries[0:80]), '.', color = 'orangered')\n",
    "\n",
    "plt.ylim(0.975,1.004)\n",
    "plt.xlim(0, len(timeseries))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Relative flux', fontsize = 18)\n",
    "plt.xlabel('Integration number', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33802cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smoothed version to use for background + 1/f corrections:\n",
    "smoothed_petit_transit = median_filter(timeseries / np.median(timeseries[0:80]), 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1543a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3.5))\n",
    "\n",
    "plt.plot(timeseries / np.median(timeseries[0:80]), '.', color = 'orangered')\n",
    "plt.plot(smoothed_petit_transit, '-', color = 'cornflowerblue')\n",
    "\n",
    "plt.ylim(0.975,1.004)\n",
    "plt.xlim(0, len(timeseries))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Relative flux', fontsize = 18)\n",
    "plt.xlabel('Integration number', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1588c29",
   "metadata": {},
   "source": [
    "Phew! Nice-centered transit. Let's jump to spectral tracing & extraction now\n",
    "\n",
    "## 1. Tracing & Extraction\n",
    "\n",
    "### 1.1 Spectral tracing\n",
    "\n",
    "Let's go to spectral tracing first. To this end, we define some CCF parameters to define the double-gaussian we will cross-correlate against the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_parameters = [-7.5, 3.0, 7.5, 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags1, ccf1 = ts.spectroscopy.get_ccf(np.arange(median_tso.shape[0]), median_tso[:, 2043], \n",
    "                                         function = 'double gaussian', parameters = ccf_parameters)\n",
    "lags2, ccf2 = ts.spectroscopy.get_ccf(np.arange(median_tso.shape[0]), median_tso[:, 1750], \n",
    "                                         function = 'double gaussian', parameters = ccf_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lags1, ccf1)\n",
    "plt.xlim(30,150)\n",
    "\n",
    "idx = np.where(np.max(ccf1) == ccf1)[0]\n",
    "ystart1 = lags1[idx][0]\n",
    "print(ystart1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ddf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lags2, ccf2)\n",
    "\n",
    "idx_large = np.where(lags2>200)[0]\n",
    "ccf2 = np.array(ccf2)\n",
    "\n",
    "idx = np.where( np.max(ccf2[idx_large]) == ccf2[idx_large] )[0]\n",
    "\n",
    "ystart2 = lags2[idx_large][idx][0]\n",
    "print(ystart2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = ts.spectroscopy.trace_spectrum(median_tso, np.zeros(median_tso.shape), \n",
    "                                           xstart = 2043, ystart = ystart1, xend = 4, \n",
    "                                           ccf_function = 'double gaussian', \n",
    "                                           ccf_parameters = ccf_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc825a",
   "metadata": {},
   "source": [
    "Now Order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_end, x2_start = 600, 1750\n",
    "\n",
    "x2, y2 = ts.spectroscopy.trace_spectrum(median_tso, np.zeros(median_tso.shape), \n",
    "                                           xstart = x2_start, ystart = ystart2, xend = x2_end, \n",
    "                                           ccf_function = 'double gaussian', \n",
    "                                           ccf_parameters = ccf_parameters, \n",
    "                                           y_tolerance = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5735cb6",
   "metadata": {},
   "source": [
    "Let's see how we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ace665",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "im = plt.imshow(median_tso, origin = 'lower', aspect = 'auto')\n",
    "\n",
    "plt.plot(x1, y1, color = 'orangered', lw = 3)\n",
    "plt.plot(x2, y2, color = 'cornflowerblue', lw = 3)\n",
    "\n",
    "im.set_clim(2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ceb78",
   "metadata": {},
   "source": [
    "Not very nice. Problem is the trace goes off after column about 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280280b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_knots1 = [[6, 1200-5], [1200, 1500-5], [1500, 1700-5],[1700, 2041]]\n",
    "nknots1 = [4,2,3,4]\n",
    "\n",
    "x_knots2 = [[601, 850-5], [850, 1100-5],[1100,1749]]\n",
    "nknots2 = [2, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sfit1 = ts.utils.fit_spline(x1, y1, nknots = nknots1, x_knots = x_knots1)\n",
    "_, sfit2 = ts.utils.fit_spline(x2, y2, nknots = nknots2, x_knots = x_knots2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a5a7e",
   "metadata": {},
   "source": [
    "Let's check these fits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "im = plt.imshow(median_tso, origin = 'lower', aspect = 'auto')\n",
    "\n",
    "plt.plot(x1, sfit1, color = 'orangered', lw = 3)\n",
    "plt.plot(x2, sfit2, color = 'cornflowerblue', lw = 3)\n",
    "\n",
    "im.set_clim(2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9a5c8",
   "metadata": {},
   "source": [
    "Nice and smooth! Let's define those as the y's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = sfit1, sfit2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f1d05",
   "metadata": {},
   "source": [
    "Let's get the times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22dc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.append(tso1.int_times['int_mid_BJD_TDB'], tso2.int_times['int_mid_BJD_TDB'])\n",
    "times = np.append(times, tso3.int_times['int_mid_BJD_TDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a792cfe",
   "metadata": {},
   "source": [
    "## 2. 1/f and sky/zodii background substraction\n",
    "\n",
    "Let's correct for the zodiacal background first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bkg = np.load('model_background256.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e4b9b",
   "metadata": {},
   "source": [
    "Is the same region as the other still working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2423cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "im = plt.imshow(median_tso, origin = 'lower')\n",
    "im.set_clim(0,8)\n",
    "plt.xlim(500,1000)\n",
    "plt.ylim(200,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38bf1c2",
   "metadata": {},
   "source": [
    "That works! Let's scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_postage = median_tso[210:250,500:800]\n",
    "model_bkg_postage = model_bkg[210:250,500:800]\n",
    "\n",
    "ratio = bkg_postage / model_bkg_postage\n",
    "ratio = ratio.flatten()\n",
    "\n",
    "idx_sorted = np.argsort(ratio)\n",
    "npixels = len(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b63cc",
   "metadata": {},
   "source": [
    "Let's see how the background distribution looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2294343",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_percentile, upper_percentile = 0.25, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a29339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_index = np.arange(len(ratio))\n",
    "plt.plot(pixel_index, ratio[idx_sorted])\n",
    "idx_lower = int(npixels*lower_percentile)\n",
    "idx_upper = int(npixels*upper_percentile)\n",
    "plt.plot(pixel_index[idx_lower:idx_upper], ratio[idx_sorted][idx_lower:idx_upper])\n",
    "plt.ylim(0.44,0.5)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Data / Model', fontsize = 18)\n",
    "plt.xlabel('Pixel index', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ratio, '.')\n",
    "plt.ylim(0.44,0.5)\n",
    "\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Data / Model', fontsize = 18)\n",
    "plt.xlabel('Pixel index', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ratio = np.median(ratio[idx_sorted][idx_lower:idx_upper])\n",
    "print(median_ratio)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ratio, '.')\n",
    "plt.plot([0, len(ratio)], [median_ratio, median_ratio])\n",
    "plt.ylim(0.44,0.5)\n",
    "\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Data / Model', fontsize = 18)\n",
    "plt.xlabel('Pixel index', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pixels = bkg_postage.flatten()\n",
    "bkg_substracted_pixels = bkg_postage.flatten() - model_bkg_postage.flatten() * median_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(bkg_substracted_pixels))\n",
    "print(np.median(original_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d85f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_original = np.where( (bkg_postage.flatten() < 10.5)&(bkg_postage.flatten() > 1.0))[0]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(original_pixels[non_outliers_original], label = 'original')\n",
    "plt.plot(bkg_substracted_pixels[non_outliers_original], label = 'corrected')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abdfd6",
   "metadata": {},
   "source": [
    "Cool! Let's apply that ratio we found to the data. First to the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(211)\n",
    "im = plt.imshow(median_tso, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(2,10)\n",
    "\n",
    "plt.subplot(212)\n",
    "im = plt.imshow(median_tso - model_bkg * median_ratio, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-3,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698611c5",
   "metadata": {},
   "source": [
    "Nice! Now, let's explore the level or 1/f noise in a background corrected integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "bkg_corrected_frame = tso[0, :, :] - model_bkg * median_ratio\n",
    "\n",
    "im = plt.imshow(bkg_corrected_frame, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18052444",
   "metadata": {},
   "source": [
    "Note the \"banding\"? That's 1/f noise. Now, this is not easy to remove in SOSS. \n",
    "\n",
    "In theory, if we had \"background pixels\" it would be easy to remove _part_ of the problem on a column-to-column basis, but these regions are hard to find because almost the entire SOSS frame is filled with flux. \n",
    "\n",
    "There's a trick I discovered, however. Assuming the noise from each frame is independant, the median frame should have a _much_ reduced 1/f noise level. Also, removing the median frame from each _individual_ frame should give me back basically the detector noise only. Let's get the out-of-transit median frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd67b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace here integrations before and after transit:\n",
    "int_before_transit = 100\n",
    "int_after_transit = 220\n",
    "\n",
    "bkg_corrected_oot_integrations = np.vstack((tso[:int_before_transit, :, :] - model_bkg * median_ratio, \\\n",
    "                              tso[int_after_transit:, :, :] - model_bkg * median_ratio))\n",
    "\n",
    "bkg_corrected_median_oot = np.nanmedian(bkg_corrected_oot_integrations, axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485130d8",
   "metadata": {},
   "source": [
    "Now let's subtract this to the individual frame we showed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(211)\n",
    "im = plt.imshow(bkg_corrected_frame, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)\n",
    "\n",
    "plt.subplot(212)\n",
    "im = plt.imshow(bkg_corrected_frame - bkg_corrected_median_oot, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ed631",
   "metadata": {},
   "source": [
    "See how this allows us to \"see\" the banding much more clearly? This leaves us basically only with detector-level effects. We can use this frame to correct our original frame. We write a function that does exactly this following pixels close to the trace. Let's check the technique out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_1f(median_frame, frame, x, y, min_bkg = 20, max_bkg = 35, mask = None, scale_factor = 1., return_1f = False):\n",
    "    \"\"\"\n",
    "    This. Needs. A. zodii-bkg-corrected. Frame as input :).\n",
    "    \"\"\"\n",
    "    \n",
    "    new_frame = np.copy(frame)\n",
    "    \n",
    "    ms = frame - median_frame * scale_factor\n",
    "    \n",
    "    if return_1f:\n",
    "        \n",
    "        one_over_f = np.zeros(len(x))\n",
    "    \n",
    "    # Go column-by-column substracting values around the trace:\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        column = x[i]\n",
    "        row = int(y[i])\n",
    "        \n",
    "        min_row = np.max([0, row - 35])\n",
    "        max_row = np.min([256, row + 35])\n",
    "        \n",
    "        bkg = np.append(ms[min_row:row-20, column], ms[row+20:max_row, column])\n",
    "        new_frame[:, column] = new_frame[:, column] - np.nanmedian(bkg)\n",
    "        \n",
    "        if return_1f:\n",
    "            \n",
    "            one_over_f[i] = np.nanmedian(bkg)\n",
    "        \n",
    "    if return_1f:\n",
    "        \n",
    "        return one_over_f, new_frame\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b0737",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d63e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_over_f, new_frame = correct_1f(bkg_corrected_median_oot, \\\n",
    "                                   tso[0, :, :]  - model_bkg * median_ratio, \\\n",
    "                                   x1, y1, \\\n",
    "                                   scale_factor = smoothed_petit_transit[0], \\\n",
    "                                   return_1f = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90274a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,20))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(x1, one_over_f, color = 'black')\n",
    "im.set_clim(-5,5)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('1/f Rate (DN/s)', fontsize = 18)\n",
    "plt.xlim(0, 2048)\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(x1, y1 + 35, color = 'orangered')\n",
    "plt.plot(x1, y1 + 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 35, color = 'orangered')\n",
    "im = plt.imshow(bkg_corrected_frame - bkg_corrected_median_oot, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Pixel (cross-dispersion)', fontsize = 18)\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(x1, y1 + 35, color = 'orangered')\n",
    "plt.plot(x1, y1 + 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 35, color = 'orangered')\n",
    "im = plt.imshow(bkg_corrected_frame, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(x1, y1 + 35, color = 'orangered')\n",
    "plt.plot(x1, y1 + 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 20, color = 'orangered')\n",
    "plt.plot(x1, y1 - 35, color = 'orangered')\n",
    "im = plt.imshow(new_frame, origin = 'lower', aspect = 'auto')\n",
    "im.set_clim(-1,1)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Pixel (cross-dispersion)', fontsize = 18)\n",
    "\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel('Pixel (cross-dispersion)', fontsize = 18)\n",
    "plt.xlabel('Pixel (wavelength direction)', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6006e81b",
   "metadata": {},
   "source": [
    "Let's apply this same thing to every spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra1_15 = np.zeros([tso.data.shape[0], len(x1)])\n",
    "spectra1_15_err = np.zeros([tso.data.shape[0], len(x1)])\n",
    "\n",
    "spectra2_15 = np.zeros([tso.data.shape[0], len(x2)])\n",
    "spectra2_15_err = np.zeros([tso.data.shape[0], len(x2)])\n",
    "\n",
    "for i in range(tso.shape[0]):\n",
    "    \n",
    "    bkg_subs_frame = correct_1f(bkg_corrected_median_oot, \\\n",
    "                                tso[i, :, :]  - model_bkg * median_ratio, \\\n",
    "                                x1, y1, \\\n",
    "                                scale_factor = smoothed_petit_transit[i])\n",
    "    \n",
    "    spectra1_15[i, :], spectra1_15_err[i, :] = ts.spectroscopy.getSimpleSpectrum(bkg_subs_frame, \n",
    "                                                                                 x1,\n",
    "                                                                                 y1, \n",
    "                                                                                 15, \n",
    "                                                                                 error_data=tso_err[i, :, :], \n",
    "                                                                                 correct_bkg=False)  \n",
    "\n",
    "    bkg_subs_frame = correct_1f(bkg_corrected_median_oot, \\\n",
    "                                tso[i, :, :]  - model_bkg * median_ratio, \\\n",
    "                                x2, y2, \\\n",
    "                                scale_factor = smoothed_petit_transit[i])\n",
    "    \n",
    "    spectra2_15[i, :], spectra2_15_err[i, :] = ts.spectroscopy.getSimpleSpectrum(bkg_subs_frame, \n",
    "                                                                                 x2,\n",
    "                                                                                 y2, \n",
    "                                                                                 15, \n",
    "                                                                                 error_data=tso_err[i, :, :], \n",
    "                                                                                 correct_bkg=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0edbf",
   "metadata": {},
   "source": [
    "Plot the extracted spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    plt.plot(spectra1_15[i,:], color = 'orangered', alpha = 0.1)\n",
    "    plt.plot(spectra2_15[i,:], color = 'cornflowerblue', alpha = 0.1)\n",
    "    \n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Pixel', fontsize = 18)\n",
    "plt.ylabel('DN /s ', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79fc9f",
   "metadata": {},
   "source": [
    "Close-up to see the transit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    plt.plot(spectra1_15[i,:], color = 'orangered', alpha = 0.1)\n",
    "    plt.plot(spectra2_15[i,:], color = 'cornflowerblue', alpha = 0.1)\n",
    "    \n",
    "plt.xlim(1600,1750)\n",
    "plt.ylim(4200,4800)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Pixel', fontsize = 18)\n",
    "plt.ylabel('DN /s ', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d776fe8",
   "metadata": {},
   "source": [
    "Nice. Let's form a master scaled spectrum that then we'll scale back to each integration to correct bad columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_spectra1 = np.zeros(spectra1_15.shape)\n",
    "master_spectra2 = np.zeros(spectra2_15.shape)\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    master_spectra1[i, :] = spectra1_15[i,:] / np.nanmedian(spectra1_15[i,:])\n",
    "    master_spectra2[i, :] = spectra2_15[i,:] / np.nanmedian(spectra2_15[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d53031",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    plt.plot(master_spectra1[i,:], color = 'orangered', alpha = 0.1)\n",
    "    plt.plot(master_spectra2[i,:], color = 'cornflowerblue', alpha = 0.1)\n",
    "    \n",
    "plt.xlim(1300,1750)\n",
    "plt.ylim(1.8,3.8)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Pixel', fontsize = 18)\n",
    "plt.ylabel('DN /s ', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e84d4",
   "metadata": {},
   "source": [
    "Get median spectrum and error at each pixel so we can scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_spectrum1 = np.zeros(spectra1_15.shape[1])\n",
    "sigma_master_spectrum1 = np.zeros(spectra1_15.shape[1])\n",
    "master_spectrum2 = np.zeros(spectra2_15.shape[1])\n",
    "sigma_master_spectrum2 = np.zeros(spectra2_15.shape[1])\n",
    "\n",
    "for i in range(spectra1_15.shape[1]):\n",
    "    \n",
    "    median1 = np.nanmedian(master_spectra1[:, i])\n",
    "    master_spectrum1[i], sigma_master_spectrum1[i] = median1, \\\n",
    "                                                     1.2533*ts.utils.get_mad_sigma(median1, master_spectra1[:, i])\n",
    "\n",
    "for i in range(spectra2_15.shape[1]):\n",
    "    median2 = np.nanmedian(master_spectra2[:, i])\n",
    "    master_spectrum2[i], sigma_master_spectrum2[i] = median2, \\\n",
    "                                                     1.2533*ts.utils.get_mad_sigma(median2, master_spectra2[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62fc6e",
   "metadata": {},
   "source": [
    "Check that errors make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78251cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(master_spectrum1 - 5*sigma_master_spectrum1, 'b--')\n",
    "plt.plot(master_spectrum1 + 5*sigma_master_spectrum1, 'b--')\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    plt.plot(master_spectra1[i,:], color = 'orangered', alpha = 0.1)\n",
    "    plt.plot(master_spectra2[i,:], color = 'cornflowerblue', alpha = 0.1)\n",
    "    \n",
    "plt.xlim(1300,1750)\n",
    "plt.ylim(1.8,3.8)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Pixel', fontsize = 18)\n",
    "plt.ylabel('DN /s ', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370aeff6",
   "metadata": {},
   "source": [
    "Awesome! Now, go through all integrations, scale the median spectrum and replace any 5-sigma outliers. Let's first test it on an example integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "integration = 70\n",
    "\n",
    "# Get median to scale:\n",
    "median = np.median(spectra1_15[integration, :])\n",
    "\n",
    "# Scale master spectrum and sigma:\n",
    "model = master_spectrum1 * median\n",
    "sigma = sigma_master_spectrum1 * median\n",
    "\n",
    "# Plot both:\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(spectra1_15[integration, :] - model)\n",
    "plt.plot(5*sigma, 'r--')\n",
    "plt.plot(-5*sigma, 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88024b27",
   "metadata": {},
   "source": [
    "Works nicely! Let's apply this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_spectra1 = np.copy(spectra1_15)\n",
    "corrected_spectra2 = np.copy(spectra2_15)\n",
    "\n",
    "corrected_spectra1_err = np.copy(spectra1_15_err)\n",
    "corrected_spectra2_err = np.copy(spectra2_15_err)\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    # First Order 1. Get median to scale:\n",
    "    median = np.median(spectra1_15[i, :])\n",
    "\n",
    "    # Scale master spectrum and sigma:\n",
    "    model = master_spectrum1 * median\n",
    "    sigma = sigma_master_spectrum1 * median\n",
    "    \n",
    "    # Identify bad pixels/columns:\n",
    "    residuals = np.abs(spectra1_15[i, :] - model)\n",
    "    idx_bad = np.where(residuals > 5 * sigma)[0]\n",
    "    \n",
    "    # Replace:\n",
    "    if len(idx_bad) != 0:\n",
    "        \n",
    "        corrected_spectra1[i, idx_bad] = model[idx_bad]\n",
    "        corrected_spectra1_err[i, idx_bad] = sigma[idx_bad]\n",
    "        \n",
    "    # Repeat for Order 2:\n",
    "    median = np.median(spectra2_15[i, :])\n",
    "\n",
    "    # Scale master spectrum and sigma:\n",
    "    model = master_spectrum2 * median\n",
    "    sigma = sigma_master_spectrum2 * median\n",
    "    \n",
    "    # Identify bad pixels/columns:\n",
    "    residuals = np.abs(spectra2_15[i, :] - model)\n",
    "    idx_bad = np.where(residuals > 5 * sigma)[0]\n",
    "    \n",
    "    # Replace:\n",
    "    if len(idx_bad) != 0:\n",
    "        \n",
    "        corrected_spectra2[i, idx_bad] = model[idx_bad]\n",
    "        corrected_spectra2_err[i, idx_bad] = sigma[idx_bad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2cf661",
   "metadata": {},
   "source": [
    "Let's see how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1546734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i in range(spectra1_15.shape[0]):\n",
    "    \n",
    "    plt.plot(corrected_spectra1[i,:], color = 'orangered', alpha = 0.1)\n",
    "    plt.plot(corrected_spectra2[i,:], color = 'cornflowerblue', alpha = 0.1)\n",
    "    \n",
    "plt.xlim(0, 2048)\n",
    "plt.ylim(0, 5000)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel('Pixel', fontsize = 18)\n",
    "plt.ylabel('DN /s ', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225caf0",
   "metadata": {},
   "source": [
    "That looks great! Let's package them up (and save results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbe515",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_solution1 = np.loadtxt('order1_wavelength_solution.txt', unpack=True)\n",
    "wavelength_solution2 = np.loadtxt('order2_wavelength_solution.txt', unpack=True)\n",
    "wavelength_solution3 = np.loadtxt('order3_wavelength_solution.txt', unpack=True)\n",
    "\n",
    "spectra = {}\n",
    "spectra['order1'] = {}\n",
    "spectra['order2'] = {}\n",
    "spectra['order1']['wavelength'] = wavelength_solution1[4:2044]\n",
    "spectra['order2']['wavelength'] = wavelength_solution2[x2_end:x2_start+1][600:]\n",
    "\n",
    "spectra['order1']['spectra'] = []\n",
    "spectra['order2']['spectra'] = []\n",
    "spectra['order1']['errors'] = []\n",
    "spectra['order2']['errors'] = []\n",
    "\n",
    "for i in range(tso.shape[0]):\n",
    "\n",
    "    spectra['order1']['spectra'].append(corrected_spectra1[i, :])\n",
    "    spectra['order2']['spectra'].append(corrected_spectra2[i, 600:])\n",
    "    spectra['order1']['errors'].append(corrected_spectra1_err[i, :])\n",
    "    spectra['order2']['errors'].append(corrected_spectra2_err[i, 600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('stellar_spectra.pkl'):\n",
    "    \n",
    "    filehandler = open(\"stellar_spectra.pkl\",\"wb\")\n",
    "    pickle.dump(spectra ,filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db801a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spectra['order1']['wavelength'], spectra['order1']['spectra'][0])\n",
    "\n",
    "plt.plot(spectra['order2']['wavelength'], spectra['order2']['spectra'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71bcc0",
   "metadata": {},
   "source": [
    "## 3. Lightcurve packaging and fitting\n",
    "\n",
    "Let's pack the wavelength dependant lightcurves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lightcurves:\n",
    "lcs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba352dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_order1 = True\n",
    "\n",
    "if regenerate_order1:\n",
    "\n",
    "    order = 'order1'\n",
    "    get_white_light = True\n",
    "    lcs[order] = {}\n",
    "\n",
    "    # This if true below is just because im lazy and dont want to take tabs back\n",
    "    if True:\n",
    "\n",
    "            if get_white_light:\n",
    "\n",
    "                # Get white-light lightcurve first:\n",
    "                lcs[order+' white light'] = {}\n",
    "                lc = np.array([])\n",
    "                lcerr = np.array([])\n",
    "\n",
    "                for i in range(len(spectra[order]['spectra'])):\n",
    "                    lc = np.append(lc, np.sum(spectra[order]['spectra'][i]))\n",
    "                    lcerr = np.append(lcerr, np.sqrt(np.sum(spectra[order]['errors'][i]**2)))\n",
    "\n",
    "                lcs[order+' white light']['flux'] = np.copy(lc)\n",
    "                lcs[order+' white light']['errors'] = np.copy(lcerr)\n",
    "\n",
    "            # Start saving from the smallest wavelength and up:\n",
    "            idx_non_zero = np.where( (spectra[order]['wavelength'] != 0.0) & ~(np.isnan(spectra[order]['wavelength']))  )[0]\n",
    "            current_wavelength = np.min(spectra[order]['wavelength'][idx_non_zero])\n",
    "\n",
    "            while True:\n",
    "\n",
    "                idx = np.where(spectra[order]['wavelength'] == current_wavelength)[0]\n",
    "                lc = np.array([])\n",
    "                lcerr = np.array([])\n",
    "\n",
    "                for i in range(len(spectra[order]['spectra'])):\n",
    "\n",
    "                    lc = np.append(lc, spectra[order]['spectra'][i][idx])\n",
    "                    lcerr = np.append(lcerr, spectra[order]['errors'][i][idx])\n",
    "\n",
    "                lcs[order][current_wavelength] = {}\n",
    "                lcs[order][current_wavelength]['flux'] = np.copy(lc)\n",
    "                lcs[order][current_wavelength]['errors'] = np.copy(lcerr)\n",
    "\n",
    "                # Go to the next wavelengths:\n",
    "                idx_next = np.where((spectra[order]['wavelength'] != current_wavelength) & (spectra[order]['wavelength'] > current_wavelength))[0]\n",
    "\n",
    "                if len(idx_next) == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    current_wavelength = np.min(spectra[order]['wavelength'][idx_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ff5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_order2 = True\n",
    "\n",
    "if regenerate_order2:\n",
    "\n",
    "    order = 'order2'\n",
    "    get_white_light = True\n",
    "    lcs[order] = {}\n",
    "\n",
    "    # This if true below is just because im lazy and dont want to take tabs back\n",
    "    if True:\n",
    "\n",
    "            if get_white_light:\n",
    "\n",
    "                # Get white-light lightcurve first:\n",
    "                lcs[order+' white light'] = {}\n",
    "                lc = np.array([])\n",
    "                lcerr = np.array([])\n",
    "\n",
    "                for i in range(len(spectra[order]['spectra'])):\n",
    "                    lc = np.append(lc, np.sum(spectra[order]['spectra'][i]))\n",
    "                    lcerr = np.append(lcerr, np.sqrt(np.sum(spectra[order]['errors'][i]**2)))\n",
    "\n",
    "                lcs[order+' white light']['flux'] = np.copy(lc)\n",
    "                lcs[order+' white light']['errors'] = np.copy(lcerr)\n",
    "\n",
    "            # Start saving from the smallest wavelength and up:\n",
    "            idx_non_zero = np.where( (spectra[order]['wavelength'] != 0.0) & ~(np.isnan(spectra[order]['wavelength']))  )[0]\n",
    "            current_wavelength = np.min(spectra[order]['wavelength'][idx_non_zero])\n",
    "\n",
    "            while True:\n",
    "\n",
    "                idx = np.where(spectra[order]['wavelength'] == current_wavelength)[0]\n",
    "                lc = np.array([])\n",
    "                lcerr = np.array([])\n",
    "\n",
    "                for i in range(len(spectra[order]['spectra'])):\n",
    "\n",
    "                    lc = np.append(lc, spectra[order]['spectra'][i][idx])\n",
    "                    lcerr = np.append(lcerr, spectra[order]['errors'][i][idx])\n",
    "\n",
    "                lcs[order][current_wavelength] = {}\n",
    "                lcs[order][current_wavelength]['flux'] = np.copy(lc)\n",
    "                lcs[order][current_wavelength]['errors'] = np.copy(lcerr)\n",
    "\n",
    "                # Go to the next wavelengths:\n",
    "                idx_next = np.where((spectra[order]['wavelength'] != current_wavelength) & (spectra[order]['wavelength'] > current_wavelength))[0]\n",
    "\n",
    "                if len(idx_next) == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    current_wavelength = np.min(spectra[order]['wavelength'][idx_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed183d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs['times'] = times + 2400000.5\n",
    "t = lcs['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca34cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('lcs.pkl'):\n",
    "    \n",
    "    filehandler = open(\"lcs.pkl\",\"wb\")\n",
    "    pickle.dump(lcs ,filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75315c53",
   "metadata": {},
   "source": [
    "### 3.1 Get lightcurve residual maps & lightcurve plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's iterate then to get all the lightcurves:\n",
    "matrices = {}\n",
    "ntimes = len(t)\n",
    "\n",
    "for order in ['order1', 'order2']:\n",
    "\n",
    "    # Create the matrix for each order. First, extract wavelengths, and number of wavelengths:\n",
    "    matrices[order+' wavelengths'] = list(lcs[order].keys())\n",
    "    nwavs = len(lcs[order].keys())\n",
    "    print(order, nwavs)\n",
    "\n",
    "    # Create matrix that will store fluxes:\n",
    "    matrices[order] = np.zeros([nwavs, ntimes])\n",
    "\n",
    "    for i in range(nwavs):\n",
    "        wavelength = matrices[order+' wavelengths'][i]\n",
    "        norm_lc = lcs[order][wavelength]['flux'] / np.median(lcs[order][wavelength]['flux'])\n",
    "        matrices[order][i,:] = (norm_lc - 1.)*1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f57755",
   "metadata": {},
   "source": [
    "Little plot to guess a time-of-transit center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3.5))\n",
    "\n",
    "plt.plot(t - np.mean(t+0.015), timeseries / np.median(timeseries[0:80]), '.', color = 'orangered')\n",
    "\n",
    "plt.ylim(0.975,1.004)\n",
    "#plt.xlim(0, len(timeseries))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Relative flux', fontsize = 18)\n",
    "plt.xlabel('Time from mid-transit (days)', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac86a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define period of the exoplanet:\n",
    "period = 3.4252602\n",
    "# Time-of-transit center:\n",
    "transit_center = np.mean(t+0.015)\n",
    "# Update transit center to this day:\n",
    "n = np.ceil((t[0] - transit_center) / period)\n",
    "transit_center = transit_center + n * period\n",
    "# Planet-to-star radius ratio:\n",
    "rprs = 0.1186\n",
    "# Transit duration in days:\n",
    "transit_duration = 2.4264/24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = juliet.utils.get_phases(t, period, transit_center)\n",
    "times_hours = phases * period * 24.\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# First, order 1:\n",
    "#plt.title('Order 1 lightcurves', fontsize = 50)\n",
    "plt.xlabel('Wavelength (microns)', fontsize = 28)\n",
    "plt.ylabel('Time from $T_c$ (hours)', fontsize = 28)\n",
    "im1 = ax1.imshow(np.abs(matrices['order1'].T), interpolation='none', cmap='Reds', aspect = 'auto')\n",
    "im1.set_clim(1000,25000)\n",
    "\n",
    "# X axis:\n",
    "ticks = np.arange(0, len(matrices['order1 wavelengths']), 250)\n",
    "ticklabels = [\"{:0.2f}\".format(matrices['order1 wavelengths'][i]) for i in ticks]\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(ticklabels, fontsize=20)\n",
    "\n",
    "# Y axis:\n",
    "ticks = np.arange(0, len(t),93)\n",
    "ticklabels = [\"{:0.0f}\".format(times_hours[i]) for i in ticks]\n",
    "ax1.set_yticks(ticks)\n",
    "ax1.set_yticklabels(ticklabels, fontsize=20)\n",
    "\n",
    "# Colorbar:\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "cbar = fig.colorbar(im1, shrink = 0.08, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.ax.get_yaxis().labelpad = 20\n",
    "cbar.ax.set_ylabel('ppm', rotation=270, fontsize = 19)\n",
    "\n",
    "plt.figure(figsize=(18,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# First, order 1:\n",
    "#plt.title('Order 1 lightcurves', fontsize = 50)\n",
    "plt.xlabel('Wavelength (microns)', fontsize = 28)\n",
    "plt.ylabel('Time from $T_c$ (hours)', fontsize = 28)\n",
    "im1 = ax1.imshow(np.abs(matrices['order2'].T), interpolation='none', cmap='Blues', aspect = 'auto')\n",
    "im1.set_clim(1000,25000)\n",
    "\n",
    "# X axis:\n",
    "ticks = np.arange(0, len(matrices['order2 wavelengths']), 250)\n",
    "ticklabels = [\"{:0.2f}\".format(matrices['order2 wavelengths'][i]) for i in ticks]\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(ticklabels, fontsize=20)\n",
    "\n",
    "# Y axis:\n",
    "ticks = np.arange(0, len(t),93)\n",
    "ticklabels = [\"{:0.0f}\".format(times_hours[i]) for i in ticks]\n",
    "ax1.set_yticks(ticks)\n",
    "ax1.set_yticklabels(ticklabels, fontsize=20)\n",
    "\n",
    "# Colorbar:\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "cbar = fig.colorbar(im1, shrink = 0.08, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.ax.get_yaxis().labelpad = 20\n",
    "cbar.ax.set_ylabel('ppm', rotation=270, fontsize = 19)\n",
    "\n",
    "plt.figure(figsize=(18,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa63b85",
   "metadata": {},
   "source": [
    "White-light lightcurve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_integrations = np.arange(len(times))\n",
    "idx_oot = np.where((t_integrations<100)|(t_integrations>250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23edb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3.5))\n",
    "\n",
    "wl = {}\n",
    "counter = 1\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "\n",
    "    plt.subplot(int('12'+str(counter)))\n",
    "\n",
    "    flux, flux_err = lcs[order+' white light']['flux'], lcs[order+' white light']['errors']\n",
    "    # idx = np.where((~np.isnan(flux)) & (flux>0))[0]\n",
    "\n",
    "    flux, flux_err = flux / np.nanmedian( flux[idx_oot] ), flux_err / np.nanmedian( flux[idx_oot] )\n",
    "\n",
    "    plt.errorbar(times_hours, flux, flux_err, fmt = '.', color = color, ms = 5, elinewidth = 1, label = order)\n",
    "    \n",
    "    wl[order] = {}\n",
    "    wl[order]['times'], wl[order]['f'], wl[order]['ferr'] = t, flux, flux_err\n",
    "    \n",
    "\n",
    "    # Plotting details\n",
    "    plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "\n",
    "    plt.ylim(0.983,1.002)\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    if counter == 2:\n",
    "        plt.yticks([], fontsize=14)\n",
    "    else:\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "    rms = ts.utils.get_mad_sigma(np.median(flux[idx_oot] - 1.), flux[idx_oot] - 1.)  * 1e6\n",
    "    rms_predicted = np.median( flux_err[idx_oot] ) * 1e6\n",
    "    plt.text(-3.3, 0.9965, '{0:.1f} ppm'.format(rms), fontsize = 20)\n",
    "    plt.title('O'+order[1:-1]+' '+order[-1]+' white-light lightcurve', fontsize = 20)\n",
    "    plt.xlabel('Time from predicted transit center (hours)', fontsize = 19)\n",
    "    if counter == 1:\n",
    "        plt.ylabel('Relative flux', fontsize = 19)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa501e4",
   "metadata": {},
   "source": [
    "Close-up out-of-transit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3.5))\n",
    "\n",
    "wl = {}\n",
    "counter = 1\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "\n",
    "    plt.subplot(int('12'+str(counter)))\n",
    "\n",
    "    flux, flux_err = lcs[order+' white light']['flux'], lcs[order+' white light']['errors']\n",
    "    # idx = np.where((~np.isnan(flux)) & (flux>0))[0]\n",
    "\n",
    "    flux, flux_err = flux / np.nanmedian( flux[idx_oot] ), flux_err / np.nanmedian( flux[idx_oot] )\n",
    "\n",
    "    plt.errorbar(times_hours, flux, flux_err, fmt = '.', color = color, ms = 5, elinewidth = 1, label = order)\n",
    "    \n",
    "    wl[order] = {}\n",
    "    wl[order]['times'], wl[order]['f'], wl[order]['ferr'] = t, flux, flux_err\n",
    "    \n",
    "\n",
    "    # Plotting details\n",
    "    plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "\n",
    "    plt.ylim(1-0.001,1+0.001)\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    if counter == 2:\n",
    "        plt.yticks([], fontsize=14)\n",
    "    else:\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "    rms = ts.utils.get_mad_sigma(np.median(flux[idx_oot] - 1.), flux[idx_oot] - 1.)  * 1e6\n",
    "    rms_predicted = np.median( flux_err[idx_oot] ) * 1e6\n",
    "    #plt.text(-4.5, 0.995, '{0:.1f} ppm'.format(rms), fontsize = 20)\n",
    "    plt.title('O'+order[1:-1]+' '+order[-1]+' white-light lightcurve', fontsize = 20)\n",
    "    plt.xlabel('Time from predicted transit center (hours)', fontsize = 19)\n",
    "    if counter == 1:\n",
    "        plt.ylabel('Relative flux', fontsize = 19)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e44b9",
   "metadata": {},
   "source": [
    "Pretty stable! Quite remarkable. The errorbars are much smaller than the scatter in the actual data expected from Poisson + uncorrelated read noise. Part of that extra scatter might be 1/f noise, but part of that might also be instrumental systematics: let's try to find some more regressors that might give us some clues on what those instrumental systematics might be!\n",
    "\n",
    "### 3.2 Searching for regressors\n",
    "\n",
    "The first suspect for regressors is the FWHM. SOSS' cross-dispersion profile is very special as it has a sort-of-a-weak-lens that spreads the light in that direction. Let's measure it as a function of wavelength and time. Below is a custom function from the `transitspectroscopy` package that gets you the FWHM following the trace both as a function of time and the median FWHM (what we call the \"super\" FWHM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trace_fwhm function returns two arrays; one (fwhms1) that gives the \n",
    "fwhms1, super_fwhm1 = ts.spectroscopy.trace_fwhm(tso, x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ae22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhms2, super_fwhm2 = ts.spectroscopy.trace_fwhm(tso, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2760d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3.5))\n",
    "\n",
    "wl_fwhms = {}\n",
    "wl_fwhms['order1'] = super_fwhm1\n",
    "wl_fwhms['order2'] = super_fwhm2\n",
    "\n",
    "counter = 1\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "\n",
    "    plt.subplot(int('12'+str(counter)))\n",
    "\n",
    "    plt.plot(times_hours, wl_fwhms[order], color = color, label = order)\n",
    "\n",
    "    # Plotting details\n",
    "    plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    if counter == 2:\n",
    "        plt.yticks([], fontsize=14)\n",
    "    else:\n",
    "        plt.yticks(fontsize=14)\n",
    "        \n",
    "    plt.ylim(-0.03,0.02)\n",
    "\n",
    "    plt.title('O'+order[1:-1]+' '+order[-1]+' FWHM', fontsize = 20)\n",
    "    plt.xlabel('Time from predicted transit center (hours)', fontsize = 19)\n",
    "    if counter == 1:\n",
    "        plt.ylabel('FWHM change', fontsize = 19)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59af062",
   "metadata": {},
   "source": [
    "Woah, interesting! The FWHM actually varies quite a lot, but there is one point at about 1.5 hours in which it abruptly changes: that's most likely a [\"tilt\" event](https://outerspace.stsci.edu/display/JTEWG/Tilt+events+in+TSOs+tracker)! Could this explain any part of the scatter in the data? Let's see these plots side by side (grey is FWHM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3.5))\n",
    "\n",
    "wl = {}\n",
    "counter = 1\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "\n",
    "    plt.subplot(int('12'+str(counter)))\n",
    "\n",
    "    \n",
    "    plt.plot(times_hours, -wl_fwhms[order] * 0.04 + 1., color = 'grey', label = order)\n",
    "    \n",
    "    flux, flux_err = lcs[order+' white light']['flux'], lcs[order+' white light']['errors']\n",
    "    # idx = np.where((~np.isnan(flux)) & (flux>0))[0]\n",
    "\n",
    "    flux, flux_err = flux / np.nanmedian( flux[idx_oot] ), flux_err / np.nanmedian( flux[idx_oot] )\n",
    "\n",
    "    plt.errorbar(times_hours, flux, flux_err, fmt = '.', color = color, ms = 5, elinewidth = 1, label = order)\n",
    "    \n",
    "    wl[order] = {}\n",
    "    wl[order]['times'], wl[order]['f'], wl[order]['ferr'] = t, flux, flux_err\n",
    "    \n",
    "\n",
    "    # Plotting details\n",
    "    plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "\n",
    "    plt.ylim(1-0.001,1+0.001)\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "\n",
    "    if counter == 2:\n",
    "        plt.yticks([], fontsize=14)\n",
    "    else:\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "    rms = ts.utils.get_mad_sigma(np.median(flux[idx_oot] - 1.), flux[idx_oot] - 1.)  * 1e6\n",
    "    rms_predicted = np.median( flux_err[idx_oot] ) * 1e6\n",
    "    #plt.text(-4.5, 0.995, '{0:.1f} ppm'.format(rms), fontsize = 20)\n",
    "    plt.title('O'+order[1:-1]+' '+order[-1]+' white-light lightcurve', fontsize = 20)\n",
    "    plt.xlabel('Time from predicted transit center (hours)', fontsize = 19)\n",
    "    if counter == 1:\n",
    "        plt.ylabel('Relative flux', fontsize = 19)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac428561",
   "metadata": {},
   "source": [
    "Doesn't seem like it really --- but we can check by fitting the data later with this as a regressor. There are many other variables we could track (centroid motions, for instance, trace rotation, etc.) but we don't cover that here in the interest of time. Left as an excercise to the reader!\n",
    "\n",
    "## 3.3 Looking at wavelength-dependent lightcurves\n",
    "\n",
    "Let's look at a handful of wavelength-dependant lightcurves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,10))\n",
    "delta = 0.02\n",
    "\n",
    "counter = 0\n",
    "\n",
    "pixels = [0.851826263252849,\n",
    "          1.2046122921163056,\n",
    "          1.409253295937408,\n",
    "          1.6051478358481832,\n",
    "          1.850487238906237,\n",
    "          2.1002466503233057, \n",
    "          2.400461499033153]\n",
    "\n",
    "colormap = plt.get_cmap('Reds')\n",
    "\n",
    "color = [colormap(k) for k in np.linspace(0.4, 1.0, len(pixels))]\n",
    "\n",
    "for i,c in zip(pixels, color):\n",
    "\n",
    "    lc, lcerr = lcs['order1'][i]['flux'], lcs['order1'][i]['errors']\n",
    "    rel_lc = lc / np.median(lc)\n",
    "    rel_lc_err = lcerr / np.median(lc)\n",
    "\n",
    "    xbin, ybin, ybinerr = juliet.utils.bin_data(times_hours,  rel_lc, 30)\n",
    "\n",
    "    plt.errorbar(times_hours, rel_lc + counter * delta, rel_lc_err, fmt = '.', \\\n",
    "                 alpha = 0.5, zorder = 1, elinewidth = 1, color = c)\n",
    "\n",
    "    plt.errorbar(xbin, ybin + counter * delta, ybinerr, fmt = 'o', ms = 10, mfc = 'white', mec = 'black', ecolor = 'black',\n",
    "                 elinewidth = 2, zorder = 4)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "plt.ylim(0.97, 1.15)\n",
    "plt.xticks(fontsize = 23)\n",
    "plt.yticks(fontsize = 23)\n",
    "plt.xlabel('Time from mid-transit (hours)', fontsize = 25)\n",
    "plt.ylabel('Relative flux + offset', fontsize = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,10))\n",
    "delta = 0.025\n",
    "\n",
    "counter = 0\n",
    "\n",
    "pixels = [0.6033095046373803, \n",
    "          0.6727569280605509, \n",
    "          0.7319645489257725, \n",
    "          0.7819995466168165, \n",
    "          0.8311994568673701,\n",
    "          0.8428133996500791]\n",
    "\n",
    "colormap = plt.get_cmap('Blues')\n",
    "\n",
    "color = [colormap(k) for k in np.linspace(0.4, 1.0, len(pixels))]\n",
    "\n",
    "for i,c in zip(pixels, color):\n",
    "    \n",
    "    lc, lcerr = lcs['order2'][i]['flux'], lcs['order2'][i]['errors']\n",
    "    rel_lc = lc / np.median(lc) \n",
    "    rel_lc_err = lcerr / np.median(lc)\n",
    "    \n",
    "    idx = np.where(rel_lc >0.97)[0]\n",
    "    rel_lc = rel_lc[idx]\n",
    "    rel_lc_err = rel_lc_err[idx]\n",
    "    \n",
    "    xbin, ybin, ybinerr = juliet.utils.bin_data(times_hours[idx],  rel_lc, 40)\n",
    "    \n",
    "    plt.errorbar(times_hours[idx], rel_lc + counter * delta, rel_lc_err, fmt = '.', \\\n",
    "                 alpha = 0.5, zorder = 1, elinewidth = 1, color = c)\n",
    "    \n",
    "    plt.errorbar(xbin, ybin + counter * delta, ybinerr, fmt = 'o', ms = 10, mfc = 'white', mec = 'black', ecolor = 'black', \n",
    "                 elinewidth = 2, zorder = 4)\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "plt.xlim(np.min(times_hours), np.max(times_hours))\n",
    "plt.ylim(0.97, 1.15)\n",
    "plt.xticks(fontsize = 23)\n",
    "plt.yticks(fontsize = 23)\n",
    "plt.xlabel('Time from mid-transit (hours)', fontsize = 25)\n",
    "plt.ylabel('Relative flux + offset', fontsize = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a83ff",
   "metadata": {},
   "source": [
    "Pretty! Let's jump to white-light lightcurve transit fitting.\n",
    "\n",
    "### 3.4 White-light lightcurve fitting\n",
    "\n",
    "Let's set some priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the parameters to be fit:\n",
    "params = ['P_p1', 't0_p1', 'a_p1', 'b_p1', 'q1_SOSS', 'q2_SOSS', 'ecc_p1', 'omega_p1',\n",
    "          'p_p1', 'mdilution_SOSS', 'mflux_SOSS', 'sigma_w_SOSS', 'GP_sigma_SOSS', \\\n",
    "          'GP_malpha0_SOSS', 'GP_malpha1_SOSS']\n",
    "\n",
    "# Distributions:\n",
    "dists = ['fixed', 'normal', 'normal', 'truncatednormal', 'uniform', 'uniform', 'fixed', 'fixed',\n",
    "         'uniform', 'fixed', 'normal', 'loguniform', 'loguniform', \\\n",
    "         'exponential', 'exponential']\n",
    "\n",
    "# Hyperparameters:\n",
    "hyperps = [period, [transit_center,0.2], [8.84, 0.5], [0.749, 0.1, 0., 1.], [0., 1.], [0.,1.], 0., 90.0,\n",
    "           [0., 0.2], 1.0, [0., 0.1], [10., 1000.], [10., 1000.], \\\n",
    "           [1.], [1.]]\n",
    "\n",
    "priors = juliet.generate_priors(params, dists, hyperps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28a509",
   "metadata": {},
   "source": [
    "Set GP regressors (plus, standarize them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_regressors(x):\n",
    "    \n",
    "    new_x = (x - np.mean(x)) / np.sqrt(np.var(x))\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_regressors = {}\n",
    "gp_regressors['SOSS'] = np.zeros([len(t), 2])\n",
    "gp_regressors['SOSS'][:, 0] = standarize_regressors(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dea36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_results = {}\n",
    "for order in ['order1', 'order2']:\n",
    "    \n",
    "    print('Fitting ',order)\n",
    "    times, fluxes, fluxes_error = {}, {}, {}\n",
    "    \n",
    "    times['SOSS'], fluxes['SOSS'], fluxes_error['SOSS'] = wl[order]['times'], \\\n",
    "                                                          wl[order]['f'], \\\n",
    "                                                          wl[order]['ferr']\n",
    "    \n",
    "    # GP regressor:\n",
    "    gp_regressors['SOSS'][:, 1] = standarize_regressors(wl_fwhms[order])\n",
    "    \n",
    "    # Perform juliet fits:\n",
    "    wl_results[order] = {}\n",
    "    wl_results[order]['dataset'] = juliet.load(priors=priors, t_lc=times, y_lc=fluxes, \\\n",
    "                                               yerr_lc=fluxes_error, GP_regressors_lc = gp_regressors,\\\n",
    "                                               out_folder=order+'_'+'GP-fwhm-white-light-square-root', \\\n",
    "                                               ld_laws = 'squareroot', george_hodlr = False)\n",
    "        \n",
    "    wl_results[order]['result'] = wl_results[order]['dataset'].fit(sampler = 'dynamic_dynesty', \\\n",
    "                                                                   bound = 'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ca2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_center = np.median(wl_results[order]['result'].posteriors['posterior_samples']['t0_p1'])\n",
    "\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    \n",
    "    normalized_time = (wl[order]['times'] - transit_center) * 24\n",
    "    \n",
    "    sigma_SOSS = np.median(wl_results[order]['result'].posteriors['posterior_samples']['sigma_w_SOSS']*1e-6)\n",
    "    \n",
    "    total_errors = np.sqrt(sigma_SOSS**2 + wl_results[order]['dataset'].errors_lc['SOSS']**2)\n",
    "    \n",
    "    plt.errorbar(normalized_time, \\\n",
    "                 wl_results[order]['dataset'].data_lc['SOSS'], \\\n",
    "                 yerr = total_errors, \\\n",
    "                 fmt = '.', color = color, ms = 4, elinewidth = 1, zorder = 1)\n",
    "    \n",
    "    # Evaluate model:\n",
    "    transit_model, transit_up68, transit_low68  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True)\n",
    "    \n",
    "    transit_model, transit_up99, transit_low99  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True, alpha = 0.99)\n",
    "        \n",
    "    plt.plot(normalized_time, transit_model, color = 'black', lw=3, zorder=2)\n",
    "        \n",
    "    plt.fill_between(normalized_time, transit_up68, transit_low68, \\\n",
    "                     color=color,alpha=0.5, zorder=3)\n",
    "    \n",
    "    plt.fill_between(normalized_time, transit_up99, transit_low99, \\\n",
    "                     color=color,alpha=0.5, zorder=3)\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim(np.min(normalized_time), np.max(normalized_time))\n",
    "    plt.xlabel('Time from mid-transit (hours)', fontsize = 19)\n",
    "    plt.ylabel('Relative flux', fontsize = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_center = np.median(wl_results[order]['result'].posteriors['posterior_samples']['t0_p1'])\n",
    "\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    \n",
    "    normalized_time = (wl[order]['times'] - transit_center) * 24\n",
    "    \n",
    "    sigma_SOSS = np.median(wl_results[order]['result'].posteriors['posterior_samples']['sigma_w_SOSS']*1e-6)\n",
    "    \n",
    "    total_errors = np.sqrt(sigma_SOSS**2 + wl_results[order]['dataset'].errors_lc['SOSS']**2)\n",
    "    \n",
    "    plt.errorbar(normalized_time, \\\n",
    "                 wl_results[order]['dataset'].data_lc['SOSS'], \\\n",
    "                 yerr = total_errors, \\\n",
    "                 fmt = '.', color = color, ms = 4, elinewidth = 1, zorder = 1)\n",
    "    \n",
    "    # Evaluate model:\n",
    "    transit_model, transit_up68, transit_low68  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True)\n",
    "    \n",
    "    transit_model, transit_up99, transit_low99  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True, alpha = 0.99)\n",
    "        \n",
    "    plt.plot(normalized_time, transit_model, color = 'black', lw=3, zorder=2)\n",
    "        \n",
    "    plt.fill_between(normalized_time, transit_up68, transit_low68, \\\n",
    "                     color=color,alpha=0.5, zorder=3)\n",
    "    \n",
    "    plt.fill_between(normalized_time, transit_up99, transit_low99, \\\n",
    "                     color=color,alpha=0.5, zorder=3)\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim(np.min(normalized_time), np.max(normalized_time))\n",
    "    plt.xlabel('Time from mid-transit (hours)', fontsize = 19)\n",
    "    plt.ylabel('Relative flux', fontsize = 19)\n",
    "    plt.ylim(1-0.001,1+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_center = np.median(wl_results[order]['result'].posteriors['posterior_samples']['t0_p1'])\n",
    "residuals = {}\n",
    "residuals_errors = {}\n",
    "\n",
    "for order,color in [('order1','orangered'),('order2','cornflowerblue')]:\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    \n",
    "    normalized_time = (wl[order]['times'] - transit_center) * 24\n",
    "    \n",
    "    # Evaluate model:\n",
    "    transit_model, transit_up68, transit_low68  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True)\n",
    "    \n",
    "    transit_model, transit_up99, transit_low99  = \\\n",
    "                   wl_results[order]['result'].lc.evaluate('SOSS', return_err=True, alpha = 0.99)\n",
    "    \n",
    "    sigma_SOSS = np.median(wl_results[order]['result'].posteriors['posterior_samples']['sigma_w_SOSS'])*1e-6\n",
    "        \n",
    "    plt.errorbar(normalized_time, \\\n",
    "                 (wl_results[order]['dataset'].data_lc['SOSS'] - transit_model)*1e6, \\\n",
    "                 yerr = np.sqrt(wl_results[order]['dataset'].errors_lc['SOSS']**2 + sigma_SOSS**2)*1e6, \\\n",
    "                 fmt = '.', color = color, ms = 4, elinewidth = 1, zorder = 1)\n",
    "    \n",
    "    residuals[order] = (wl_results[order]['dataset'].data_lc['SOSS'] - transit_model)*1e6\n",
    "    residuals_errors[order] = np.sqrt(wl_results[order]['dataset'].errors_lc['SOSS']**2 + sigma_SOSS**2)*1e6\n",
    "    \n",
    "    plt.plot([-5,5],[0,0], '--', color = 'black')\n",
    "    \n",
    "    print(ts.utils.get_mad_sigma(np.nanmedian((wl_results[order]['dataset'].data_lc['SOSS'] - transit_model)*1e6), \\\n",
    "                                 (wl_results[order]['dataset'].data_lc['SOSS'] - transit_model)*1e6), 'ppm precision for',order)\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylim(-1000,1000)\n",
    "    plt.xlim(np.min(normalized_time), np.max(normalized_time))\n",
    "    #plt.title('White-lightcurves --- '+order+' residuals', fontsize = 20)\n",
    "    plt.xlabel('Time from mid-transit (hours)', fontsize = 19)\n",
    "    plt.ylabel('Residuals (ppm)', fontsize = 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa2db7",
   "metadata": {},
   "source": [
    "Some Allan variance plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(x, y, n_bin):\n",
    "    \n",
    "    x_bins = []\n",
    "    y_bins = []\n",
    "    y_err_bins = []\n",
    "    \n",
    "    for i in range(0,len(x),n_bin):\n",
    "        \n",
    "        x_bins.append(np.median(x[i:i+n_bin-1]))\n",
    "        y_bins.append(np.median(y[i:i+n_bin-1]))\n",
    "        y_err_bins.append(np.sqrt(np.var(y[i:i+n_bin-1]))/np.sqrt(len(y[i:i+n_bin-1])))\n",
    "        \n",
    "    return np.array(x_bins), np.array(y_bins), np.array(y_err_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = np.arange(2,310,1)\n",
    "scatter = np.zeros(len(nbins))\n",
    "order = 'order1'\n",
    "\n",
    "for i in range(len(nbins)):\n",
    "    \n",
    "    xbin, ybin, ybinerr = bin_data(normalized_time,  residuals[order], nbins[i])\n",
    "    scatter[i] = np.sqrt(np.var(ybin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(nbins, scatter, 'o-', color = 'black')\n",
    "plt.plot(nbins, (np.sqrt(nbins[0]) * scatter[0]*0.8) / np.sqrt(nbins), '--', \\\n",
    "         color = 'orangered', lw = 3)\n",
    "#plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('RMS (ppm)', fontsize = 25)\n",
    "plt.xlabel('Bin size', fontsize = 25)\n",
    "plt.xticks([2, 10, 20, 30, 50, 100, 300], ['2', '10', '20', '30', '50', '100', '300'], fontsize=23)\n",
    "plt.yticks([10, 20, 30, 50, 100, 200], ['10', '20', '30', '50', '100', '200'], fontsize=23)\n",
    "plt.yticks(fontsize=23)\n",
    "plt.xlim(np.min(nbins),np.max(nbins))\n",
    "plt.ylim(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4fba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = np.arange(2,310,1)\n",
    "scatter = np.zeros(len(nbins))\n",
    "order = 'order2'\n",
    "\n",
    "for i in range(len(nbins)):\n",
    "    \n",
    "    xbin, ybin, ybinerr = bin_data(normalized_time,  residuals[order], nbins[i])\n",
    "    scatter[i] = np.sqrt(np.var(ybin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(nbins, scatter, 'o-', color = 'black')\n",
    "plt.plot(nbins, (np.sqrt(nbins[0]) * scatter[0]*0.8) / np.sqrt(nbins), '--', \\\n",
    "         color = 'cornflowerblue', lw = 3)\n",
    "#plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('RMS (ppm)', fontsize = 25)\n",
    "plt.xlabel('Bin size', fontsize = 25)\n",
    "plt.xticks([2, 10, 20, 30, 50, 100, 300], ['2', '10', '20', '30', '50', '100', '300'], fontsize=23)\n",
    "plt.yticks([10, 20, 30, 50, 100, 200], ['10', '20', '30', '50', '100', '200'], fontsize=23)\n",
    "plt.yticks(fontsize=23)\n",
    "plt.xlim(np.min(nbins),np.max(nbins))\n",
    "plt.ylim(1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for order in ['order1', 'order2']:\n",
    "    \n",
    "    print('\\nResults for ' + order + ':')\n",
    "    print('----------------')\n",
    "    \n",
    "    for parameters in ['t0_p1', 'p_p1', 'a_p1', 'b_p1', 'sigma_w_SOSS', 'q1_SOSS', 'q2_SOSS']:\n",
    "        \n",
    "        posteriors = wl_results[order]['result'].posteriors['posterior_samples'][parameters]\n",
    "        med, valup, valdown = juliet.utils.get_quantiles(posteriors)\n",
    "        print('\\t '+parameters + ':', med, '+', valup-med, '-', med - valdown)\n",
    "        if parameters == 'p_p1':\n",
    "            med, valup, valdown = juliet.utils.get_quantiles((posteriors**2)*1e6)\n",
    "            print('\\t transit depth:', med, '+', valup-med, '-', med - valdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3e2f1",
   "metadata": {},
   "source": [
    "These look good! Not absolutely perfect, perhaps, but good for a quick-look analysis. You can now take these results and use them to fit wavelength-dependant lightcurves on your own!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
